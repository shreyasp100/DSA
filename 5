CBOW --- 
from gensim.models import Word2Vec
import nltk
from nltk.corpus import brown
nltk.download('brown')
data = brown.sents()
model = Word2Vec(data, min_count=1, window=5) 
model.train(data, total_examples=len(data), epochs=5)
print(data)
word_vectors = model.wv
similarity = word_vectors.similarity('woman', 'man')
print(f"Similarity between 'woman' and 'man': {similarity}")

DL-4

import tensorflow as tf
import pandas as pd
import numpy as np
df = pd.read_csv('Desktop\creditcard.csv')
df.head()
df = df.drop(['Time', 'Class'], axis = 1)
df.shape

from sklearn.preprocessing import StandardScaler
scaler = StandardScaler()
df.iloc[:, :-1] = scaler.fit_transform(df.iloc[:, :-1])
df.head()

from sklearn.model_selection import train_test_split
x_train, x_test = train_test_split(df, test_size=0.2)
print("x_train shape : ", x_train.shape)
print("x_test shape : ", x_test.shape)

from keras.models import Model, Sequential
from tensorflow.keras.layers import Dense, Dropout
from tensorflow.keras import layers, models
encoder = tf.keras.models.Sequential([
 layers.Input(shape=(x_train.shape[1],)),
 layers.Dense(20, activation='relu'),
 layers.Dense(20, activation='relu'),
 layers.Dense(10, activation='relu')
])

decoder = tf.keras.models.Sequential([
 layers.Input(shape=(10,)),
 layers.Dense(20, activation='relu'),
 layers.Dense(20, activation='relu'),
 layers.Dense(x_train.shape[1], activation='linear')
])
model = tf.keras.models.Sequential([
 encoder,
 decoder,
])
model.compile(optimizer='adam', loss ='mean_squared_error')

history = model.fit(
 x_train,
 x_train,
 validation_data=(x_test,x_test),
 epochs=10,
 batch_size = 500,
 shuffle=True
)
predictions = model.predict(x_test)
mse = np.mean(np.power(x_test - predictions, 2), axis=1)
mse
threshold = np.percentile(mse, 95)
threshold
anomalies = mse > threshold
num_anomalies = np.sum(anomalies)
print(f"Number of Anomalies: {num_anomalies}")
